{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DUDL_RNN_LSTMGRU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBvSQIUDWTH/9/q9k1HQ+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamuncseru/deep_understanding_deep_learning/blob/main/DUDL_RNN_LSTMGRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XkWx897ZiG_7"
      },
      "outputs": [],
      "source": [
        "## import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore the LSTM type"
      ],
      "metadata": {
        "id": "F-VjedVaq0cD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set layer parameters\n",
        "input_size = 9      # number of features to extract (e.g., number of data channels)\n",
        "hidden_size = 16    # number of units in the hidden state\n",
        "num_layers = 2      # number of vertical stacks of hidden layers (note: only the final layer)\n",
        "\n",
        "\n",
        "# create an LSTM instance\n",
        "lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
        "print(lstm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YrzewYkq2h3",
        "outputId": "bc2bd8da-c803-4bab-fcae-77e5b49aa54b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM(9, 16, num_layers=2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## check out the source code\n",
        "??nn.LSTM"
      ],
      "metadata": {
        "id": "ZBISaE8orZ_G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set data parameters\n",
        "seqlength = 5\n",
        "batchsize = 2\n",
        "\n",
        "# create some data\n",
        "X = torch.rand(seqlength, batchsize, input_size)\n",
        "\n",
        "# create a hidden layer (typically intialized as zeros)\n",
        "H = torch.zeros(num_layers, batchsize, hidden_size)\n",
        "C = torch.zeros(num_layers, batchsize, hidden_size)\n",
        "\n",
        "# the input is actually a tuple of (hidden, cell)\n",
        "hiddeninputs = (H, C)\n",
        "\n",
        "# run some through the model and show the output sizes\n",
        "y, h = lstm(X, hiddeninputs)\n",
        "print(f'Input shape: {list(X.shape)}')\n",
        "print(f'Hidden shape: {list(h[0].shape)}')\n",
        "print(f'Cell shape: {list(h[1].shape)}')\n",
        "print(f'Output shape: {list(y.shape)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2b_aw6MrdcJ",
        "outputId": "c151b6bc-79f1-4e23-f785-6a9ad64341a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: [5, 2, 9]\n",
            "Hidden shape: [2, 2, 16]\n",
            "Cell shape: [2, 2, 16]\n",
            "Output shape: [5, 2, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the learned parameters and their sizes\n",
        "for p in lstm.named_parameters():\n",
        "    if 'weight' in p[0]:\n",
        "        print(f'{p[0]} has size {list(p[1].shape)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpGfh7Tvss7x",
        "outputId": "56ee3f82-ec88-41eb-9b0d-b6609ec9a861"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_ih_l0 has size [64, 9]\n",
            "weight_hh_l0 has size [64, 16]\n",
            "weight_ih_l1 has size [64, 16]\n",
            "weight_hh_l1 has size [64, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a DL model class"
      ],
      "metadata": {
        "id": "Ewxn4NFMtmx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMnet(nn.Module):\n",
        "    def __init__(self, input_size, num_hidden, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        # store parameters\n",
        "        self.input_size = input_size\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        ## RNN Layer\n",
        "        self.lstm = nn.LSTM(input_size, num_hidden, num_layers)\n",
        "\n",
        "        # linear layer for output\n",
        "        self.out = nn.Linear(num_hidden, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        print(f'Input: {list(x.shape)}')\n",
        "\n",
        "        # initialize hidden state for first input\n",
        "        hidden= torch.zeros(self.num_layers, batchsize, self.num_hidden)\n",
        "        print(f'Hidden: {list(hidden.shape)}')\n",
        "\n",
        "        # run through the RNN layer\n",
        "        y, hidden = self.lstm(x)\n",
        "        print(f'LSTM-out: {list(y.shape)}')\n",
        "        print(f'LSTM-hidden: {list(hidden[0].shape)}')\n",
        "        print(f'RNN-Cell: {list(hidden[1].shape)}')\n",
        "\n",
        "        # pass the RNN output through the linear output layer\n",
        "        o = self.out(y) \n",
        "        print(f'Output: {list(o.shape)}')\n",
        "\n",
        "        return o, hidden\n",
        "\n"
      ],
      "metadata": {
        "id": "9KuNjiYQtrly"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an instance of the model and inspect\n",
        "net = LSTMnet(input_size, hidden_size, num_layers)\n",
        "print(net), print(' ')\n",
        "\n",
        "# and checkout all learnable parameters\n",
        "for p in net.named_parameters():\n",
        "    print(f'{p[0]:>20} has size {list(p[1].shape)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4INqmX4vHxT",
        "outputId": "7fe135e0-ba02-4413-a83c-c7cd261e78a6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMnet(\n",
            "  (lstm): LSTM(9, 16, num_layers=2)\n",
            "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
            ")\n",
            " \n",
            "   lstm.weight_ih_l0 has size [64, 9]\n",
            "   lstm.weight_hh_l0 has size [64, 16]\n",
            "     lstm.bias_ih_l0 has size [64]\n",
            "     lstm.bias_hh_l0 has size [64]\n",
            "   lstm.weight_ih_l1 has size [64, 16]\n",
            "   lstm.weight_hh_l1 has size [64, 16]\n",
            "     lstm.bias_ih_l1 has size [64]\n",
            "     lstm.bias_hh_l1 has size [64]\n",
            "          out.weight has size [1, 16]\n",
            "            out.bias has size [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model with some fake data\n",
        "# create some data\n",
        "X = torch.rand(seqlength, batchsize, input_size)\n",
        "y = torch.rand(seqlength, batchsize, 1)\n",
        "yHat, h = net(X)\n",
        "\n",
        "# try a loss function\n",
        "lossfun = nn.MSELoss()\n",
        "lossfun(yHat, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBkSKjjjv-Cp",
        "outputId": "d6051b11-c16d-4e96-eb90-8f8163094b89"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [5, 2, 9]\n",
            "Hidden: [2, 2, 16]\n",
            "LSTM-out: [5, 2, 16]\n",
            "LSTM-hidden: [2, 2, 16]\n",
            "RNN-Cell: [2, 2, 16]\n",
            "Output: [5, 2, 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2509, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU"
      ],
      "metadata": {
        "id": "goJtfeDmwVP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a GRU instance\n",
        "gru = nn.GRU(input_size, hidden_size, num_layers)\n",
        "gru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdaqPXH_uToT",
        "outputId": "ff5cce97-97bb-4771-bc29-64df963be80d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GRU(9, 16, num_layers=2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "??nn.GRU"
      ],
      "metadata": {
        "id": "uV0KijWnujJz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create some data\n",
        "X = torch.rand(seqlength, batchsize, input_size)\n",
        "\n",
        "# create a hidden layer (typically intialized as zeros)\n",
        "H = torch.zeros(num_layers, batchsize, hidden_size)\n",
        "\n",
        "# run some through the model and show the output sizes\n",
        "y, h = gru(X, H)\n",
        "print(f'Input shape: {list(X.shape)}')\n",
        "print(f'Hidden shape: {list(h.shape)}')\n",
        "print(f'Output shape: {list(y.shape)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce79RhiTuj-j",
        "outputId": "b3787f80-48c8-4841-b49f-2c0fe9f97f6e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: [5, 2, 9]\n",
            "Hidden shape: [2, 2, 16]\n",
            "Output shape: [5, 2, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in gru.named_parameters():\n",
        "    print(f'{p[0]:>15} has size {list(p[1].shape)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbzcf67ju2yz",
        "outputId": "c043b7ce-3efc-4bc0-f681-c686b13b90be"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   weight_ih_l0 has size [48, 9]\n",
            "   weight_hh_l0 has size [48, 16]\n",
            "     bias_ih_l0 has size [48]\n",
            "     bias_hh_l0 has size [48]\n",
            "   weight_ih_l1 has size [48, 16]\n",
            "   weight_hh_l1 has size [48, 16]\n",
            "     bias_ih_l1 has size [48]\n",
            "     bias_hh_l1 has size [48]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6v7XfzdEvAj6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}