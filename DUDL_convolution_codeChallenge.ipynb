{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DUDL_convolution_codeChallenge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWigPcmpTBPMF5Jw7Q3+Vm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamuncseru/deep_understanding_deep_learning/blob/main/DUDL_convolution_codeChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V_WprW8ci79j"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample problems"
      ],
      "metadata": {
        "id": "wbjEE2vUjFO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolve an image of size 1x256x256 to produce a 1x252x84 result\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "z3P-RgDbjGum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "inChans = 1 # Grayscale\n",
        "imsize = [256, 256]\n",
        "outChans = 1\n",
        "krnSize = 7\n",
        "stride = (1, 3)\n",
        "padding = 1\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans, outChans, krnSize, stride, padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1, inChans, imsize[0], imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans, 0, 0], dtype=int)\n",
        "expectSize[1] = np.floor((imsize[0] + 2*padding-krnSize)/stride[0]) + 1\n",
        "expectSize[2] = np.floor((imsize[1] + 2*padding-krnSize)/stride[1]) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqnzPRzdjOq7",
        "outputId": "adc575cb-2a67-47d0-bcaa-f16c41c35515"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [  1 252  84]\n",
            "Empirical size: [252, 84]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real problems"
      ],
      "metadata": {
        "id": "d3Ud2ewBk1mm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Convolve an image of size 3x64x64 to produce a 10x28x28 result"
      ],
      "metadata": {
        "id": "lenzdrPdlAaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "inChans = 3\n",
        "imsize = [64, 64]\n",
        "outChans = 10\n",
        "krnSize = 9\n",
        "stride  = [2,2]\n",
        "padding = 0\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans, outChans, krnSize, stride, padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1, inChans, imsize[0], imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans, 0, 0], dtype=int)\n",
        "expectSize[1] = np.floor((imsize[0] + 2*padding-krnSize)/stride[0]) + 1\n",
        "expectSize[2] = np.floor((imsize[1] + 2*padding-krnSize)/stride[1]) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngYDxmjnlOL1",
        "outputId": "f70c8e57-1c19-4250-d925-7f81bd34fb03"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [10 28 28]\n",
            "Empirical size: [10, 28, 28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Convolve an image of size 3x196x96 to produce a 5x66x49 result"
      ],
      "metadata": {
        "id": "15H7lmq9mhKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "inChans = 3\n",
        "imsize = [196, 96]\n",
        "outChans = 5\n",
        "krnSize = 3\n",
        "stride  = [3,2]\n",
        "padding = 2\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans, outChans, krnSize, stride, padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1, inChans, imsize[0], imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans, 0, 0], dtype=int)\n",
        "expectSize[1] = np.floor((imsize[0] + 2*padding-krnSize)/stride[0]) + 1\n",
        "expectSize[2] = np.floor((imsize[1] + 2*padding-krnSize)/stride[1]) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN-zPlpmmF1X",
        "outputId": "e26c6267-67be-45d1-e2a4-04c8c2025a9d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [ 5 66 49]\n",
            "Empirical size: [5, 66, 49]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Convolve an image of size 1x32x32 to produce a 6x28x28 result"
      ],
      "metadata": {
        "id": "ExYN6ejymxOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "inChans = 1\n",
        "imsize = [32, 32]\n",
        "outChans = 6\n",
        "krnSize = 5\n",
        "stride  = [1,1]\n",
        "padding = 0\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans, outChans, krnSize, stride, padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1, inChans, imsize[0], imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans, 0, 0], dtype=int)\n",
        "expectSize[1] = np.floor((imsize[0] + 2*padding-krnSize)/stride[0]) + 1\n",
        "expectSize[2] = np.floor((imsize[1] + 2*padding-krnSize)/stride[1]) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXPHhKDCmd5E",
        "outputId": "faadeca2-5063-4854-9e24-039265d393cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [ 6 28 28]\n",
            "Empirical size: [6, 28, 28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Convolve an image of size 3x227x227 to produce a 96x55x55 result"
      ],
      "metadata": {
        "id": "B8NbF-QYnB-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "inChans = 3\n",
        "imsize = [227, 227]\n",
        "outChans = 96\n",
        "krnSize = 9\n",
        "stride  = [4,4]\n",
        "padding = 0\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans, outChans, krnSize, stride, padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1, inChans, imsize[0], imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans, 0, 0], dtype=int)\n",
        "expectSize[1] = np.floor((imsize[0] + 2*padding-krnSize)/stride[0]) + 1\n",
        "expectSize[2] = np.floor((imsize[1] + 2*padding-krnSize)/stride[1]) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_gTJWvmmfA8",
        "outputId": "0a95bfdc-4cb9-4dfc-ddb2-63102f9d2ce6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [96 55 55]\n",
            "Empirical size: [96, 55, 55]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) Convolve an image of size 3x224x224 to produce a 64x224x224 result"
      ],
      "metadata": {
        "id": "HQOvi1YKnJ5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "inChans = 3\n",
        "imsize = [224, 224]\n",
        "outChans = 64\n",
        "krnSize = 5\n",
        "stride  = [1,1]\n",
        "padding = 2\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans, outChans, krnSize, stride, padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1, inChans, imsize[0], imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans, 0, 0], dtype=int)\n",
        "expectSize[1] = np.floor((imsize[0] + 2*padding-krnSize)/stride[0]) + 1\n",
        "expectSize[2] = np.floor((imsize[1] + 2*padding-krnSize)/stride[1]) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZXsURdlmfla",
        "outputId": "d3bffa11-bc12-4f48-de7f-3f1099f5fa6a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [ 64 224 224]\n",
            "Empirical size: [64, 224, 224]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OqBudOlZpdSI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}